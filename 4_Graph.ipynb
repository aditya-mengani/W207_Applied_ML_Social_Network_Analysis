{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook's process\n",
    "\n",
    "1. Load in Crunchbase dataframes(4 merged CSVs created in `1_SS_EDA.ipynb`)\n",
    "    - Organizations: `files/output/organizations_merged.csv`\n",
    "    - Jobs: `files/output/p1_jobs.csv`\n",
    "    - Investments: `files/output/p1_investments.csv`\n",
    "    - Partner investments: `files/output/p1_investments_partner.csv`\n",
    "2. Select date\n",
    "3. Filter the dataframes by date\n",
    "4. Save filtered dataframes as separate CSVs, and then load in as SFrames\n",
    "    - Crunchbase network: `files/output/graph_temp/cb/{}_df.csv`\n",
    "    - Pledge 1% network: `files/output/graph_temp/cb/{}_df.csv`\n",
    "    - Not Pledge 1% network: `files/output/graph_temp/cb/{}_df.csv`\n",
    "5. Load SFrames into graph\n",
    "6. Reduce size of dataset by limiting degrees of freedom from Pledge 1%\n",
    "7. Create random sample of non-P1 organizations, equal to number of P1 organizations\n",
    "8. Load in updated dataframes with sample uuids\n",
    "9. Save filter  dataframes as separate CSVs, and then load in as SFrames\n",
    "    - Crunchbase network: `files/output/graph_model/cb/{}_df.csv`\n",
    "    - Pledge 1% network: `files/output/graph_model/cb/{}_df.csv`\n",
    "    - Not Pledge 1% network: `files/output/graph_model/cb/{}_df.csv`\n",
    "    - Model network: `files/output/graph_model/model/{}_df.csv`\n",
    "10. Load SFrames into graph\n",
    "11. Graph feature calculations, save to CSV\n",
    "    - Pagerank: `files/output/graph_model/model/pagerank.csv`\n",
    "\n",
    "### To be explored further\n",
    "- Applying weights to network based on edge `status`\n",
    "- Calculate another useful graph feature to include in the model\n",
    "- EDA on model graph\n",
    "\n",
    "### Model\n",
    "**p1_tag ~ `rank` + `total_funding_usd` + `employee_count` (ordinal) + `country` (nominal, 210 indicator columns) + `category_groups` (nominal, 46 indicator columns) + `days_since_founding` + ((GRAPH FEATURES))**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Importing basic data analysis packages'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import warnings\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "from datetime import datetime\n",
    "#datetime.today().strftime('%Y%m%d')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "'''Graph'''\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "from turicreate import SFrame, SGraph, pagerank, degree_counting, aggregate, visualization\n",
    "\n",
    "'''Plotting packages'''\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#%matplotlib inline\n",
    "sns.set(style='white', font_scale=1.3)\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):   \n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "def network_by_date(date, df_input, jobs_input, invest_input, invest_prtnr_input, model_uuids=[], skip_not_p1=True):\n",
    "    '''\n",
    "    This function filters down Crunchbase dataframes by date \n",
    "    to ensure that the companies/people/investments being used in modeling exist at a given time.\n",
    "\n",
    "    INPUT:\n",
    "        - `date`: string w/ format 'YEAR-MO-DY' (e.g. '2020-09-08')\n",
    "        - `df`: pandas dataframe of Crunchbase organizationss with necessary column fields:\n",
    "            * `p1_date`, `founded_on`, `closed_on`\n",
    "        - `jobs`: pandas dataframe of Crunchbase jobss with necessary column fields:\n",
    "            * `p1_date`, `started_on`, `ended_on`\n",
    "        - `invest`: pandas dataframe of Crunchbase investmentss with necessary column fields:\n",
    "            * `p1_date`, `announced_on`\n",
    "        - `invest_prtnr`: pandas dataframe of Crunchbase investments with necessary column fields:\n",
    "            * `p1_date`, `announced_on`\n",
    "        - `model_uuids`: list that contains the uuids of organizations that are used to construct the model graph\n",
    "    \n",
    "    OUTPUT:\n",
    "        - List of dataframe lists, 3 (or 4) lists of length 10: \n",
    "            * [Crunchbase neighborhood dataframes], [Pledge 1% neighborhood dataframes], \n",
    "              [~Pledge 1% neighborhood dataframes], { [Model neighborhood dataframes] }\n",
    "        - Each dataframe list contains dataframes that will be used in the next processing step:\n",
    "            0. Companies\n",
    "            1. Investors\n",
    "            2. Investments\n",
    "            3. Partner investments\n",
    "            4. Current Jobs\n",
    "            5. Former jobs\n",
    "            6. Former affiliated's new jobs\n",
    "            7. Partner investor's affiliation (if not in jobs dataframes)\n",
    "            8. Partner investor's coworkers at the investing firm\n",
    "            9. Partner investor's coworkers' partner investments\n",
    "            10. Current affiliated's old jobs\n",
    "            11. Organization nodes from edges in 2,3,6,7,9,10 if not already in 0 or 1\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # Soft copy of dataframes\n",
    "    df = df_input.copy()\n",
    "    jobs = jobs_input.copy()\n",
    "    invest = invest_input.copy()\n",
    "    invest_prtnr = invest_prtnr_input.copy()\n",
    "    \n",
    "    #*******************************************************************************************************\n",
    "    # DATE PROCESSING\n",
    "    \n",
    "    # Convert date columns to datetime\n",
    "    df['p1_date'] = pd.to_datetime(df['p1_date'], errors='coerce')\n",
    "    df['founded_on'] = pd.to_datetime(df['founded_on'], errors='coerce')\n",
    "    df['closed_on'] = pd.to_datetime(df['closed_on'], errors='coerce')\n",
    "    jobs['p1_date'] = pd.to_datetime(jobs['p1_date'], errors='coerce')\n",
    "    jobs['started_on'] = pd.to_datetime(jobs['started_on'], errors='coerce')\n",
    "    jobs['ended_on'] = pd.to_datetime(jobs['ended_on'], errors='coerce')\n",
    "    invest['p1_date'] = pd.to_datetime(invest['p1_date'], errors='coerce')\n",
    "    invest['announced_on'] = pd.to_datetime(invest['announced_on'], errors='coerce')\n",
    "    invest_prtnr['p1_date'] = pd.to_datetime(invest_prtnr['p1_date'], errors='coerce')\n",
    "    invest_prtnr['announced_on'] = pd.to_datetime(invest_prtnr['announced_on'], errors='coerce')\n",
    "    \n",
    "    # Convert input date to datetime object\n",
    "    date = pd.Timestamp(date)\n",
    "    print('\\nAS OF {}:\\n'.format(date.strftime('%B %d, %Y').upper()))\n",
    "    \n",
    "    #*******************************************************************************************************\n",
    "    # Create new row for tagging model companies\n",
    "    df['add_to_model'] = 0\n",
    "    df['add_to_model'][df['uuid'].isin(model_uuids)] = 1\n",
    "    jobs['add_to_model'] = 0\n",
    "    jobs['add_to_model'][jobs['org_uuid'].isin(model_uuids)] = 1\n",
    "    invest['add_to_model'] = 0\n",
    "    invest['add_to_model'][invest['org_uuid'].isin(model_uuids)] = 1\n",
    "    invest_prtnr['add_to_model'] = 0\n",
    "    invest_prtnr['add_to_model'][invest_prtnr['org_uuid'].isin(model_uuids)] = 1\n",
    "    \n",
    "    #*******************************************************************************************************\n",
    "    # COMPANY FILTER\n",
    "    # Crunchbase company must be founded after DATE and closed before DATE (or DATE == NaT)\n",
    "    CB_companies = df[(df['founded_on']<=date) & \n",
    "                      ((df['closed_on']>date) | (pd.isnull(df['closed_on']))) & \n",
    "                      (df['primary_role']=='company')].reset_index(drop=True)\n",
    "    \n",
    "    #*******************************************************************************************************\n",
    "    # INVESTOR FILTER:\n",
    "    # Crunchbase investor must be founded AFTER date and closed BEFORE date (or date == NaT)\n",
    "    CB_investors = df[(df['founded_on']<=date) & \n",
    "                      ((df['closed_on']>date) | (pd.isnull(df['closed_on']))) & \n",
    "                      (df['primary_role']=='investor')].reset_index(drop=True)\n",
    "    \n",
    "    #*******************************************************************************************************\n",
    "    # INVESTMENT FILTER\n",
    "    # Crunchbase investment must have taken place BEFORE date\n",
    "    CB_investments = invest[(invest['announced_on']<=date) & \n",
    "                            (invest['investor_type']=='organization')].reset_index(drop=True)\n",
    "    \n",
    "    #*******************************************************************************************************\n",
    "    # PARTNER INVESTMENT FILTER\n",
    "    # Crunchbase partner investment must have taken place BEFORE date\n",
    "    CB_investment_partners = invest_prtnr[invest_prtnr['announced_on']<=date].reset_index(drop=True)\n",
    "    \n",
    "    #*******************************************************************************************************\n",
    "    # CURRENT JOB FILTER\n",
    "    # Crunchbase job must have started BEFORE date and ended AFTER date (or date == NaT)\n",
    "    CB_jobs = jobs[(jobs['job_type'].isin(['executive','board_member','advisor','board_observer'])) & \n",
    "                      (jobs['started_on']<=date) & \n",
    "                      ((jobs['ended_on']>date) | (pd.isnull(jobs['ended_on'])))].reset_index(drop=True)\n",
    "    \n",
    "    #*******************************************************************************************************\n",
    "    # FORMER JOB FILTER\n",
    "    # Crunchbase job must have ended BEFORE date or started AFTER date\n",
    "    CB_jobs_former = jobs[(jobs['job_type'].isin(['executive','board_member','advisor','board_observer'])) & \n",
    "                          ((jobs['ended_on']<=date) | (jobs['started_on']>date))].reset_index(drop=True)\n",
    "    \n",
    "    #*******************************************************************************************************\n",
    "    # COMBINE THESE 6 (or 7) INTO LIST OF FRAMES\n",
    "    lst_of_frames = []\n",
    "    \n",
    "    # Crunchbase frames\n",
    "    CB_frames = [CB_companies,CB_investors,CB_investments,CB_investment_partners,CB_jobs,CB_jobs_former]\n",
    "    \n",
    "    # Add to list of frames\n",
    "    lst_of_frames.append(CB_frames)\n",
    "    \n",
    "    # If model_uuids are not supplied, calculate Pledge 1% neighborhood\n",
    "    if model_uuids == []:\n",
    "        P1_frames = []\n",
    "        for frame in CB_frames:\n",
    "            \n",
    "            # Pledge 1% frames must have Crunchbase assumptions in addition to an earlier pledge date\n",
    "            new_frame = frame[frame['p1_date']<=date].reset_index(drop=True).drop('add_to_model',axis=1)\n",
    "            P1_frames.append(new_frame)\n",
    "        # Add to list of frames\n",
    "        lst_of_frames.append(P1_frames)\n",
    "    \n",
    "    # If model_uuids are supplied, calculate model neighborhood\n",
    "    if model_uuids != []:\n",
    "        model_frames = []\n",
    "        for frame in CB_frames:\n",
    "            \n",
    "            # Include model dataframe if condition satisfied: either are a Pledge 1% company or tagged by model_uuids\n",
    "            new_frame=frame[(frame['p1_date']<=date) | (frame['add_to_model']==1)].reset_index(drop=True).drop('add_to_model',axis=1)\n",
    "            model_frames.append(new_frame)\n",
    "        \n",
    "        # Add to list of frames\n",
    "        lst_of_frames.append(model_frames)\n",
    "    \n",
    "    # If this boolean value is False, calculate ~Pledge 1% neighborhood\n",
    "    if skip_not_p1 is False:\n",
    "        not_P1_frames = []\n",
    "        for frame in CB_frames:\n",
    "            \n",
    "            # Non-Pledge 1% frames must have Crunchbase assumptions in addition to NaT pledge date or later pledge date\n",
    "            new_frame = frame[(pd.isnull(frame['p1_date']) | (frame['p1_date']>date))].reset_index(drop=True).drop('add_to_model',axis=1)\n",
    "            not_P1_frames.append(new_frame)\n",
    "        \n",
    "        # Add to list of frames\n",
    "        lst_of_frames.append(not_P1_frames)\n",
    "        \n",
    "    # Remove extra column 'add_to_model'\n",
    "    for idx,frame in enumerate(CB_frames):\n",
    "        CB_frames[idx] = frame.drop('add_to_model',axis=1)\n",
    "\n",
    "    #*******************************************************************************************************\n",
    "    # FORMER NEW JOB FILTER\n",
    "    print('CaLcUlAtInG... FORMER NEW JOB FILTER')\n",
    "    \n",
    "    for frame in lst_of_frames:\n",
    "        \n",
    "        # Where do the former affiliated work now?\n",
    "        former_people = frame[5].person_uuid.unique() # Pull their IDs\n",
    "        jobs_former_new = CB_frames[4][CB_frames[4].person_uuid.isin(former_people)] # Pull their current jobs from Crunchbase\n",
    "\n",
    "        # Check they're not already in the current jobs dataframe\n",
    "        # Combine into one temp data frame\n",
    "        combined_jobs = pd.concat([frame[4], jobs_former_new]).reset_index(drop=True) \n",
    "        df_gpby = combined_jobs.groupby(list(combined_jobs.columns))\n",
    "        \n",
    "        # Only count non-duplicated columns\n",
    "        idx = [x[0] for x in df_gpby.groups.values() if len(x) == 1]\n",
    "        \n",
    "        # Reindex dataframe\n",
    "        jobs_former_new = combined_jobs.reindex(idx)\n",
    "        \n",
    "        # Add to list of frames\n",
    "        frame.append(jobs_former_new)\n",
    "    \n",
    "    #*******************************************************************************************************\n",
    "    # PARTNER INVESTMENT JOB FILTER\n",
    "    print('CaLcUlAtInG... PARTNER INVESTMENT JOB FILTER')\n",
    "    \n",
    "    for frame in lst_of_frames:\n",
    "        \n",
    "        # Are the partner investment jobs already in one of the jobs dataframes? If not, we should add them.\n",
    "        \n",
    "        # Create temporary dataframe and column to make checking the intersection between dataframes easier \n",
    "        # frame[4]: current jobs | frame[5]: former jobs | frame[6]: former new jobs\n",
    "        jobs_combined = pd.concat([frame[4],frame[5],frame[6]])\n",
    "        jobs_combined['person,company'] = jobs_combined['person_uuid'] + ',' + jobs_combined['org_uuid']\n",
    "        \n",
    "        # frame[3]: partner investments\n",
    "        frame[3]['person,company'] = frame[3]['partner_uuid']+ ',' + frame[3]['investor_uuid']\n",
    "\n",
    "        # Number of unique partner investments\n",
    "        unique_PI = frame[3]['person,company'].unique()\n",
    "\n",
    "        # Overlap between PI and combined J frames, create temporary jobs view\n",
    "        # These PI are already found in J frames, so we do not need to include them\n",
    "        jobs_already_in_J = jobs_combined[jobs_combined['person,company'].isin(unique_PI)] \n",
    "\n",
    "        # This will return non intersecting value of PI with temp J\n",
    "        # These PI are not found in J, so we would like to include them\n",
    "        PI_not_in_J = np.setdiff1d(unique_PI,jobs_already_in_J['person,company'].unique())\n",
    "\n",
    "        # Need to create separate jobs dataframe for non intersecting PI/J person/company pairs\n",
    "        grouped = frame[3][frame[3]['person,company'].isin(PI_not_in_J)].groupby(['partner_uuid','partner_name','investor_uuid','investor_name']).count()\n",
    "        grouped_df = grouped.reset_index()[['partner_uuid','partner_name','investor_uuid','investor_name']]\n",
    "        grouped_df['job_type'] = 'executive'\n",
    "        \n",
    "        # Add to list of frames\n",
    "        frame.append(grouped_df)\n",
    "    \n",
    "    #*******************************************************************************************************\n",
    "    # OTHER FIRM PARNTERS\n",
    "    print('CaLcUlAtInG... OTHER FIRM PARTNER JOBS & INVESTMENTS FILTER')\n",
    "    \n",
    "    for frame in lst_of_frames:\n",
    "        \n",
    "        # OTHER FIRM PARNTERS - JOBS\n",
    "        # Who are the other partners that work at the investment firms present in the neighborhood?\n",
    "        \n",
    "        # Get the unique investor uuids associated with the dataframes\n",
    "        # frame[2]: from investments dataframe\n",
    "        unique_investor_firm_A = list(frame[2]['investor_uuid'].unique())\n",
    "        \n",
    "        # frame[3]: from partner investments dataframe\n",
    "        unique_investor_firm_B = list(frame[3]['investor_uuid'].unique())\n",
    "        partners = list(frame[3]['partner_uuid'].unique())\n",
    "        \n",
    "        # Combine to get list of unique uuids of VC firms\n",
    "        unique_firms = list(set(unique_investor_firm_A+unique_investor_firm_B))\n",
    "        \n",
    "        # Grab current jobs from Crunchbase for these investing firms\n",
    "        # Exclude duplicate partner job (already represented by partners list calculated above)\n",
    "        partner_jobs = CB_frames[4][(CB_frames[4]['org_uuid'].isin(unique_firms)) &  \n",
    "                                    ~(CB_frames[4]['person_uuid'].isin(partners))].reset_index(drop=True)\n",
    "        \n",
    "        # Check they're not already in the current/former jobs dataframe\n",
    "        # Combine into one temp data frame\n",
    "        combined_jobs = pd.concat([frame[4], partner_jobs]).reset_index(drop=True) \n",
    "        df_gpby = combined_jobs.groupby(list(combined_jobs.columns))\n",
    "        \n",
    "        # Only count non-duplicated rows\n",
    "        idx = [x[0] for x in df_gpby.groups.values() if len(x) == 1]\n",
    "        \n",
    "        # Reindex dataframe\n",
    "        partner_jobs = combined_jobs.reindex(idx)\n",
    "        \n",
    "        # Add to list of frames\n",
    "        frame.append(partner_jobs)\n",
    "        \n",
    "        # OTHER FIRM PARNTERS - PARTNER INVESTMENTS\n",
    "        # For these new partners, what companies are they invested in?\n",
    "        # Get the unique parnter uuids associated with the dataframes\n",
    "        other_partners = partner_jobs['person_uuid'].unique()\n",
    "        other_partner_investments = CB_frames[3][CB_frames[3]['partner_uuid'].isin(other_partners)]\n",
    "        \n",
    "        # Check they're not already in the partner investments dataframe\n",
    "        # Combine into one temp data frame\n",
    "        combined_jobs = pd.concat([frame[3], other_partner_investments]).reset_index(drop=True) \n",
    "        df_gpby = combined_jobs.groupby(list(combined_jobs.columns))\n",
    "        \n",
    "        # Only count non-duplicated rows\n",
    "        idx = [x[0] for x in df_gpby.groups.values() if len(x) == 1]\n",
    "        \n",
    "        # Reindex dataframe\n",
    "        other_partner_investments = combined_jobs.reindex(idx)\n",
    "        \n",
    "        # Add to list of frames\n",
    "        frame.append(other_partner_investments)\n",
    "    \n",
    "    #*******************************************************************************************************\n",
    "    # CURRENT OLD JOB FILTER\n",
    "    print('CaLcUlAtInG... CURRENT OLD JOB FILTER')\n",
    "    \n",
    "    for frame in lst_of_frames:\n",
    "        \n",
    "        # Where did the current affiliated work previously?\n",
    "        current_people = frame[4].person_uuid.unique() # Pull their IDs\n",
    "        jobs_current_old = CB_frames[5][CB_frames[5].person_uuid.isin(current_people)] # Pull their current jobs from Crunchbase\n",
    "\n",
    "        # Check they're not already in the current jobs dataframe\n",
    "        # Combine into one temp data frame\n",
    "        combined_jobs = pd.concat([frame[5], jobs_current_old]).reset_index(drop=True) \n",
    "        df_gpby = combined_jobs.groupby(list(combined_jobs.columns))\n",
    "        \n",
    "        # Only count non-duplicated columns\n",
    "        idx = [x[0] for x in df_gpby.groups.values() if len(x) == 1]\n",
    "        \n",
    "        # Reindex dataframe\n",
    "        jobs_current_old = combined_jobs.reindex(idx)\n",
    "        \n",
    "        # Add to list of frames\n",
    "        frame.append(jobs_current_old)\n",
    "        \n",
    "    #*******************************************************************************************************\n",
    "    # GET EXTRA ORG UUID ATTRIBUTES FROM INVESTMENTS & JOBS\n",
    "    print('CaLcUlAtInG... EXTRA ORGANIZATION NODES')\n",
    "    \n",
    "    CB_orgs = pd.concat([CB_companies, CB_investors])\n",
    "    \n",
    "    for frame in lst_of_frames:\n",
    "        \n",
    "        unique_orgs = []\n",
    "        \n",
    "        # Investments\n",
    "        unique_orgs.extend(list(frame[2]['investor_uuid'].unique()))\n",
    "        \n",
    "        # Partner investments\n",
    "        unique_orgs.extend(list(frame[3]['investor_uuid'].unique()))\n",
    "        \n",
    "        # Former new jobs organizations\n",
    "        unique_orgs.extend(list(frame[6]['org_uuid'].unique()))\n",
    "        \n",
    "        # Parter jobs organizations\n",
    "        unique_orgs.extend(list(frame[7]['investor_uuid'].unique()))\n",
    "        \n",
    "        # Other parter investments organizations\n",
    "        unique_orgs.extend(list(frame[9]['org_uuid'].unique()))\n",
    "        \n",
    "        # Current old jobs organizations\n",
    "        unique_orgs.extend(list(frame[10]['org_uuid'].unique()))\n",
    "        \n",
    "        # Pull their organization information from Crunchbase\n",
    "        new_org_nodes = CB_orgs[CB_orgs['uuid'].isin(list(set(unique_orgs)))]\n",
    "        \n",
    "        # Add to list of frames\n",
    "        frame.append(new_org_nodes)\n",
    "    \n",
    "    #*******************************************************************************************************\n",
    "    del df['add_to_model'], invest['add_to_model'], invest_prtnr['add_to_model'], jobs['add_to_model']\n",
    "    \n",
    "    # Output print statements\n",
    "    print('\\nCrunchbase Neighborhood')\n",
    "    print('NODES | OUTPUT FRAME 0/CB_companies {}'.format(CB_frames[0].shape))\n",
    "    print('NODES | OUTPUT FRAME 1/CB_investors {}'.format(CB_frames[1].shape))\n",
    "    print('NODES&EDGES | OUTPUT FRAME 2/CB_investments {}'.format(CB_frames[2].shape))\n",
    "    print('NODES&EDGES | OUTPUT FRAME 3/CB_investment_partners {}'.format(CB_frames[3].shape))\n",
    "    print('NODES&EDGES | OUTPUT FRAME 4/CB_jobs {}'.format(CB_frames[4].shape))\n",
    "    print('NODES&EDGES | OUTPUT FRAME 5/CB_jobs_former {}'.format(CB_frames[5].shape))\n",
    "    print('NODES&EDGES | OUTPUT FRAME 6/CB_jobs_former_new {}'.format(CB_frames[6].shape))\n",
    "    print('NODES&EDGES | OUTPUT FRAME 7/CB_jobs_partner {}'.format(CB_frames[7].shape))\n",
    "    print('NODES&EDGES | OUTPUT FRAME 8/CB_jobs_other_partners {}'.format(CB_frames[8].shape))\n",
    "    print('NODES&EDGES | OUTPUT FRAME 9/CB_invest_other_partners {}'.format(CB_frames[9].shape))\n",
    "    print('NODES&EDGES | OUTPUT FRAME 10/CB_jobs_current_old {}'.format(CB_frames[10].shape))\n",
    "    print('NODES | OUTPUT FRAME 11/CB_extra_org_nodes {}'.format(CB_frames[11].shape))\n",
    "    \n",
    "    if model_uuids != []:\n",
    "\n",
    "        print('\\nModel Neighborhood')\n",
    "        print('NODES | OUTPUT FRAME 0/model_companies {}'.format(model_frames[0].shape))\n",
    "        print('NODES | OUTPUT FRAME 1/model_investors {}'.format(model_frames[1].shape))\n",
    "        print('NODES&EDGES | OUTPUT FRAME 2/model_investments {}'.format(model_frames[2].shape))\n",
    "        print('NODES&EDGES | OUTPUT FRAME 3/model_investment_partners {}'.format(model_frames[3].shape))\n",
    "        print('NODES&EDGES | OUTPUT FRAME 4/model_jobs {}'.format(model_frames[4].shape))\n",
    "        print('NODES&EDGES | OUTPUT FRAME 5/model_jobs_former {}'.format(model_frames[5].shape))\n",
    "        print('NODES&EDGES | OUTPUT FRAME 6/model_jobs_former_new {}'.format(model_frames[6].shape))\n",
    "        print('NODES&EDGES | OUTPUT FRAME 7/model_jobs_partner {}'.format(model_frames[7].shape))\n",
    "        print('NODES&EDGES | OUTPUT FRAME 8/model_jobs_other_partners {}'.format(model_frames[8].shape))\n",
    "        print('NODES&EDGES | OUTPUT FRAME 9/model_invest_other_partners {}'.format(model_frames[9].shape))\n",
    "        print('NODES&EDGES | OUTPUT FRAME 10/model_jobs_current_old {}'.format(model_frames[10].shape))\n",
    "        print('NODES | OUTPUT FRAME 11/model_extra_org_nodes {}'.format(model_frames[11].shape))\n",
    "        \n",
    "        return CB_frames, model_frames\n",
    "    \n",
    "    print('\\nPledge 1% Neighborhood')\n",
    "    print('NODES | OUTPUT FRAME 0/P1_companies {}'.format(P1_frames[0].shape))\n",
    "    print('NODES | OUTPUT FRAME 1/P1_investors {}'.format(P1_frames[1].shape))\n",
    "    print('NODES&EDGES | OUTPUT FRAME 2/P1_investments {}'.format(P1_frames[2].shape))\n",
    "    print('NODES&EDGES | OUTPUT FRAME 3/P1_investment_partners {}'.format(P1_frames[3].shape))\n",
    "    print('NODES&EDGES | OUTPUT FRAME 4/P1_jobs {}'.format(P1_frames[4].shape))\n",
    "    print('NODES&EDGES | OUTPUT FRAME 5/P1_jobs_former {}'.format(P1_frames[5].shape))\n",
    "    print('NODES&EDGES | OUTPUT FRAME 6/P1_jobs_former_new {}'.format(P1_frames[6].shape))\n",
    "    print('NODES&EDGES | OUTPUT FRAME 7/P1_jobs_partner {}'.format(P1_frames[7].shape))\n",
    "    print('NODES&EDGES | OUTPUT FRAME 8/P1_jobs_other_partners {}'.format(P1_frames[8].shape))\n",
    "    print('NODES&EDGES | OUTPUT FRAME 9/P1_invest_other_partners {}'.format(P1_frames[9].shape))\n",
    "    print('NODES&EDGES | OUTPUT FRAME 10/P1_jobs_current_old {}'.format(P1_frames[10].shape))\n",
    "    print('NODES | OUTPUT FRAME 11/P1_extra_org_nodes {}'.format(P1_frames[11].shape))\n",
    "    \n",
    "    # Skip Not P1 Calculations\n",
    "    if skip_not_p1 is False:\n",
    "        \n",
    "        print('\\n~Pledge 1% Neighborhood')\n",
    "        print('NODES | OUTPUT FRAME 0/not_P1_companies {}'.format(not_P1_frames[0].shape))\n",
    "        print('NODES | OUTPUT FRAME 1/not_P1_investors {}'.format(not_P1_frames[1].shape))\n",
    "        print('NODES&EDGES | OUTPUT FRAME 2/not_P1_investments {}'.format(not_P1_frames[2].shape))\n",
    "        print('NODES&EDGES | OUTPUT FRAME 3/not_P1_investment_partners {}'.format(not_P1_frames[3].shape))\n",
    "        print('NODES&EDGES | OUTPUT FRAME 4/not_P1_jobs {}'.format(not_P1_frames[4].shape))\n",
    "        print('NODES&EDGES | OUTPUT FRAME 5/not_P1_jobs_former {}'.format(not_P1_frames[5].shape))\n",
    "        print('NODES&EDGES | OUTPUT FRAME 6/not_P1_jobs_former_new {}'.format(not_P1_frames[6].shape))\n",
    "        print('NODES&EDGES | OUTPUT FRAME 7/not_P1_jobs_partner {}'.format(not_P1_frames[7].shape))\n",
    "        print('NODES&EDGES | OUTPUT FRAME 8/not_P1_jobs_other_partners {}'.format(not_P1_frames[8].shape))\n",
    "        print('NODES&EDGES | OUTPUT FRAME 9/not_P1_invest_other_partners {}'.format(not_P1_frames[9].shape))\n",
    "        print('NODES&EDGES | OUTPUT FRAME 10/not_P1_jobs_current_old {}'.format(not_P1_frames[10].shape))\n",
    "        print('NODES | OUTPUT FRAME 11/not_P1_extra_org_nodes {}'.format(not_P1_frames[11].shape))\n",
    "    \n",
    "    return CB_frames, P1_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load in Crunchbase dataframes (merged CSVs created in `1_SS_EDA.ipynb`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT df=p1+org FROM CSV: files/output/organizations_merged.csv\n",
      "ORGANIZATION/df cols: ['uuid', 'name', 'type', 'rank', 'roles', 'country_code', 'region', 'status', 'category_groups_list', 'total_funding_usd', 'founded_on', 'closed_on', 'employee_count', 'primary_role', 'p1_tag', 'p1_date']\n",
      "SHAPE: (1131315, 16)\n",
      "Mem. usage decreased to 121.00 Mb (12.0% reduction)\n",
      "\n",
      "INPUT jobs FROM CSV: files/output/p1_jobs.csv\n",
      "JOBS/jobs cols: ['job_uuid', 'person_uuid', 'person_name', 'org_uuid', 'org_name', 'started_on', 'ended_on', 'is_current', 'title', 'job_type', 'p1_tag', 'p1_date']\n",
      "SHAPE: (1536376, 12)\n",
      "Mem. usage decreased to 121.00 Mb (6.0% reduction)\n",
      "\n",
      "INPUT invest FROM CSV: files/output/p1_investments.csv\n",
      "INVESTMENTS/invest cols: ['investment_uuid', 'funding_round_uuid', 'investor_uuid', 'investor_name', 'investor_type', 'is_lead_investor', 'investment_type', 'announced_on', 'raised_amount_usd', 'post_money_valuation_usd', 'investor_count', 'lead_investor_uuids', 'lead_investor_count', 'org_uuid', 'org_name', 'p1_tag', 'p1_date']\n",
      "SHAPE: (517639, 17)\n",
      "Mem. usage decreased to 54.00 Mb (19.0% reduction)\n",
      "\n",
      "INPUT invest_prtnr FROM CSV: files/output/p1_investments_partner.csv\n",
      "PARTNER INVESTMENTS/invest_prtnr cols: ['investment_uuid', 'funding_round_uuid', 'investor_uuid', 'investor_name', 'partner_uuid', 'partner_name', 'investment_type', 'announced_on', 'raised_amount_usd', 'post_money_valuation_usd', 'investor_count', 'lead_investor_uuids', 'lead_investor_count', 'org_uuid', 'org_name', 'p1_tag', 'p1_date']\n",
      "SHAPE: (89926, 17)\n",
      "Mem. usage decreased to  9.00 Mb (18.0% reduction)\n",
      "\n",
      "\n",
      "Pledge 1% UUID: fd9e2d10-a882-c6f4-737e-fd388d4ffd7c\n"
     ]
    }
   ],
   "source": [
    "# Import CSVs as Pandas DataFrames\n",
    "path = 'files/output/organizations_merged.csv'\n",
    "df = pd.read_csv(path).drop(['Unnamed: 0'],axis=1)\n",
    "print('INPUT df=p1+org FROM CSV: {}'.format(path))\n",
    "print('ORGANIZATION/df cols: {}\\nSHAPE: {}'.format(df.columns.to_list(), df.shape))\n",
    "df = reduce_mem_usage(df, verbose=True)\n",
    "\n",
    "path = 'files/output/p1_jobs.csv'\n",
    "jobs = pd.read_csv(path)\n",
    "print('\\nINPUT jobs FROM CSV: {}'.format(path))\n",
    "print('JOBS/jobs cols: {}\\nSHAPE: {}'.format(jobs.columns.to_list(), jobs.shape))\n",
    "jobs = reduce_mem_usage(jobs, verbose=True)\n",
    "\n",
    "path = 'files/output/p1_investments.csv'\n",
    "invest = pd.read_csv(path)\n",
    "print('\\nINPUT invest FROM CSV: {}'.format(path))\n",
    "print('INVESTMENTS/invest cols: {}\\nSHAPE: {}'.format(invest.columns.to_list(), invest.shape))\n",
    "invest = reduce_mem_usage(invest, verbose=True)\n",
    "\n",
    "path = 'files/output/p1_investments_partner.csv'\n",
    "invest_prtnr = pd.read_csv(path)\n",
    "print('\\nINPUT invest_prtnr FROM CSV: {}'.format(path))\n",
    "print('PARTNER INVESTMENTS/invest_prtnr cols: {}\\nSHAPE: {}'.format(invest_prtnr.columns.to_list(), invest_prtnr.shape))\n",
    "invest_prtnr = reduce_mem_usage(invest_prtnr, verbose=True)\n",
    "\n",
    "print('\\n\\nPledge 1% UUID: {}'.format(df[df['name']=='Pledge 1%'].uuid.values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Select date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2020-09-08'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Filter the dataframes by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AS OF SEPTEMBER 08, 2020:\n",
      "\n",
      "CaLcUlAtInG... FORMER NEW JOB FILTER\n",
      "CaLcUlAtInG... PARTNER INVESTMENT JOB FILTER\n",
      "CaLcUlAtInG... OTHER FIRM PARTNER JOBS & INVESTMENTS FILTER\n",
      "CaLcUlAtInG... CURRENT OLD JOB FILTER\n",
      "CaLcUlAtInG... EXTRA ORGANIZATION NODES\n",
      "\n",
      "Crunchbase Neighborhood\n",
      "NODES | OUTPUT FRAME 0/CB_companies (825393, 16)\n",
      "NODES | OUTPUT FRAME 1/CB_investors (31499, 16)\n",
      "NODES&EDGES | OUTPUT FRAME 2/CB_investments (453058, 17)\n",
      "NODES&EDGES | OUTPUT FRAME 3/CB_investment_partners (89926, 18)\n",
      "NODES&EDGES | OUTPUT FRAME 4/CB_jobs (395270, 12)\n",
      "NODES&EDGES | OUTPUT FRAME 5/CB_jobs_former (182483, 12)\n",
      "NODES&EDGES | OUTPUT FRAME 6/CB_jobs_former_new (483629, 12)\n",
      "NODES&EDGES | OUTPUT FRAME 7/CB_jobs_partner (11771, 5)\n",
      "NODES&EDGES | OUTPUT FRAME 8/CB_jobs_other_partners (434370, 12)\n",
      "NODES&EDGES | OUTPUT FRAME 9/CB_invest_other_partners (161382, 18)\n",
      "NODES&EDGES | OUTPUT FRAME 10/CB_jobs_current_old (289847, 12)\n",
      "NODES | OUTPUT FRAME 11/CB_extra_org_nodes (225184, 17)\n",
      "\n",
      "Pledge 1% Neighborhood\n",
      "NODES | OUTPUT FRAME 0/P1_companies (6615, 16)\n",
      "NODES | OUTPUT FRAME 1/P1_investors (141, 16)\n",
      "NODES&EDGES | OUTPUT FRAME 2/P1_investments (12005, 17)\n",
      "NODES&EDGES | OUTPUT FRAME 3/P1_investment_partners (3628, 18)\n",
      "NODES&EDGES | OUTPUT FRAME 4/P1_jobs (11758, 12)\n",
      "NODES&EDGES | OUTPUT FRAME 5/P1_jobs_former (6653, 12)\n",
      "NODES&EDGES | OUTPUT FRAME 6/P1_jobs_former_new (17224, 12)\n",
      "NODES&EDGES | OUTPUT FRAME 7/P1_jobs_partner (1460, 5)\n",
      "NODES&EDGES | OUTPUT FRAME 8/P1_jobs_other_partners (25036, 12)\n",
      "NODES&EDGES | OUTPUT FRAME 9/P1_invest_other_partners (33517, 18)\n",
      "NODES&EDGES | OUTPUT FRAME 10/P1_jobs_current_old (13729, 12)\n",
      "NODES | OUTPUT FRAME 11/P1_extra_org_nodes (24993, 17)\n"
     ]
    }
   ],
   "source": [
    "cb_frames,p1_frames = network_by_date(date, df, jobs, invest, invest_prtnr)\n",
    "\n",
    "# List of Pledge 1% uuids\n",
    "global p1_companies_uuid\n",
    "p1_companies_uuid = []\n",
    "p1_companies_uuid.extend(list(p1_frames[0]['uuid'].unique()))\n",
    "p1_companies_uuid.extend(list(p1_frames[1]['uuid'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Save filtered dataframes as separate CSVs, and then load in as SFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save filtered dataframes as separate CSVs & load in nodes, edges as SFrames\n",
    "\n",
    "<a href='https://apple.github.io/turicreate/docs/api/generated/turicreate.SFrame.html'>turicreate.SFrame</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SAVED TO CSV', 'files/output/graph_temp/cb/0_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_temp/cb/1_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_temp/cb/2_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_temp/cb/3_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_temp/cb/4_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_temp/cb/5_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_temp/cb/6_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_temp/cb/7_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_temp/cb/8_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_temp/cb/9_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_temp/cb/10_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_temp/cb/11_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_temp/p1/0_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_temp/p1/1_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_temp/p1/2_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_temp/p1/3_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_temp/p1/4_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_temp/p1/5_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_temp/p1/6_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_temp/p1/7_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_temp/p1/8_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_temp/p1/9_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_temp/p1/10_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_temp/p1/11_df.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/0_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/0_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 1.77537 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 1.77537 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,float,str,str,str,str,str,float,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 290126 lines. Lines per second: 152419</pre>"
      ],
      "text/plain": [
       "Read 290126 lines. Lines per second: 152419"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/0_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/0_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 825393 lines in 4.02785 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 825393 lines in 4.02785 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/1_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/1_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.176784 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.176784 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,float,str,str,str,str,str,float,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/1_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/1_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 31499 lines in 0.146789 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 31499 lines in 0.146789 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/2_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/2_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 2.42817 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 2.42817 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,float,float,float,str,float,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 201405 lines. Lines per second: 111051</pre>"
      ],
      "text/plain": [
       "Read 201405 lines. Lines per second: 111051"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/2_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/2_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 453058 lines in 3.36421 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 453058 lines in 3.36421 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/3_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/3_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 1.29737 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 1.29737 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,float,float,float,str,float,str,str,float,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/3_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/3_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 89926 lines in 0.730147 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 89926 lines in 0.730147 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/4_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/4_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 1.70362 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 1.70362 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 279331 lines. Lines per second: 167271</pre>"
      ],
      "text/plain": [
       "Read 279331 lines. Lines per second: 167271"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/4_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/4_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 395270 lines in 2.0448 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 395270 lines in 2.0448 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/5_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/5_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.968403 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.968403 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/5_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/5_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 182483 lines in 1.05142 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 182483 lines in 1.05142 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/6_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/6_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 1.57007 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 1.57007 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 280191 lines. Lines per second: 79588</pre>"
      ],
      "text/plain": [
       "Read 280191 lines. Lines per second: 79588"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/6_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/6_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 483629 lines in 4.41603 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 483629 lines in 4.41603 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/7_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/7_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.046784 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.046784 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/7_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/7_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 11771 lines in 0.040157 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 11771 lines in 0.040157 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/8_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/8_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 1.37699 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 1.37699 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 279269 lines. Lines per second: 189345</pre>"
      ],
      "text/plain": [
       "Read 279269 lines. Lines per second: 189345"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/8_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/8_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 434370 lines in 2.21039 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 434370 lines in 2.21039 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/9_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/9_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 1.7342 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 1.7342 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,float,float,float,str,float,str,str,float,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 138777 lines. Lines per second: 105890</pre>"
      ],
      "text/plain": [
       "Read 138777 lines. Lines per second: 105890"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/9_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/9_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 161382 lines in 1.41121 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 161382 lines in 1.41121 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/10_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/10_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 1.38916 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 1.38916 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/10_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/10_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 289847 lines in 1.39145 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 289847 lines in 1.39145 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/11_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/11_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 1.18418 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 1.18418 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,float,str,str,str,str,str,float,str,str,str,str,int,str,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/11_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/11_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 225184 lines in 1.10385 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 225184 lines in 1.10385 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/0_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/0_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.043395 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.043395 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,float,str,str,str,str,str,float,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/0_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/0_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 6615 lines in 0.028438 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 6615 lines in 0.028438 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/1_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/1_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.008173 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.008173 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,float,str,str,str,str,str,float,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/1_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/1_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 141 lines in 0.007271 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 141 lines in 0.007271 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/2_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/2_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.086248 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.086248 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,float,float,float,str,float,str,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/2_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/2_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 12005 lines in 0.060694 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 12005 lines in 0.060694 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/3_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/3_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.038103 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.038103 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,float,float,float,str,float,str,str,float,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/3_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/3_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 3628 lines in 0.024635 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 3628 lines in 0.024635 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/4_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/4_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.089693 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.089693 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/4_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/4_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 11758 lines in 0.050262 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 11758 lines in 0.050262 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/5_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/5_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.047075 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.047075 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/5_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/5_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 6653 lines in 0.028598 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 6653 lines in 0.028598 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/6_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/6_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.092248 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.092248 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/6_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/6_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 17224 lines in 0.082034 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 17224 lines in 0.082034 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/7_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/7_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.012166 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.012166 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/7_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/7_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1460 lines in 0.009307 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1460 lines in 0.009307 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/8_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/8_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.126138 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.126138 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/8_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/8_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 25036 lines in 0.116886 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 25036 lines in 0.116886 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/9_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/9_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.258922 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.258922 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,float,float,float,str,float,str,str,float,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/9_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/9_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 33517 lines in 0.265909 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 33517 lines in 0.265909 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/10_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/10_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.081969 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.081969 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/10_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/10_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 13729 lines in 0.063468 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 13729 lines in 0.063468 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/11_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/11_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.142404 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.142404 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,float,str,str,str,str,str,float,str,str,str,str,int,str,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/11_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/11_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 24993 lines in 0.109801 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 24993 lines in 0.109801 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx, frame in enumerate(cb_frames):\n",
    "    path = 'files/output/graph_temp/cb/{}_df.csv'.format(idx)\n",
    "    print('SAVED TO CSV', path)\n",
    "    frame.to_csv(path, index=False)\n",
    "for idx, frame in enumerate(p1_frames):\n",
    "    path = 'files/output/graph_temp/p1/{}_df.csv'.format(idx)\n",
    "    print('SAVED TO CSV', path)\n",
    "    frame.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/0_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/0_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 1.77468 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 1.77468 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,float,str,str,str,str,str,float,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 290126 lines. Lines per second: 149236</pre>"
      ],
      "text/plain": [
       "Read 290126 lines. Lines per second: 149236"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/0_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/0_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 825393 lines in 4.03836 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 825393 lines in 4.03836 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/1_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/1_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.179124 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.179124 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,float,str,str,str,str,str,float,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/1_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/1_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 31499 lines in 0.156069 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 31499 lines in 0.156069 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/2_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/2_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 1.55835 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 1.55835 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,float,float,float,str,float,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 201405 lines. Lines per second: 122507</pre>"
      ],
      "text/plain": [
       "Read 201405 lines. Lines per second: 122507"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/2_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/2_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 453058 lines in 2.77484 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 453058 lines in 2.77484 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/3_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/3_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.754792 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.754792 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,float,float,float,str,float,str,str,float,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/3_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/3_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 89926 lines in 0.830923 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 89926 lines in 0.830923 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/4_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/4_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 1.62241 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 1.62241 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 279331 lines. Lines per second: 122406</pre>"
      ],
      "text/plain": [
       "Read 279331 lines. Lines per second: 122406"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/4_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/4_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 395270 lines in 2.67083 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 395270 lines in 2.67083 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/5_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/5_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 1.63076 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 1.63076 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/5_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/5_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 182483 lines in 1.00151 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 182483 lines in 1.00151 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/6_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/6_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 1.46684 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 1.46684 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 280191 lines. Lines per second: 174433</pre>"
      ],
      "text/plain": [
       "Read 280191 lines. Lines per second: 174433"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/6_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/6_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 483629 lines in 2.20607 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 483629 lines in 2.20607 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/7_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/7_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.045826 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.045826 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/7_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/7_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 11771 lines in 0.06433 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 11771 lines in 0.06433 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/8_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/8_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 2.11231 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 2.11231 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 279269 lines. Lines per second: 170113</pre>"
      ],
      "text/plain": [
       "Read 279269 lines. Lines per second: 170113"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/8_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/8_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 434370 lines in 2.29204 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 434370 lines in 2.29204 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/9_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/9_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 1.43398 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 1.43398 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,float,float,float,str,float,str,str,float,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 138777 lines. Lines per second: 109410</pre>"
      ],
      "text/plain": [
       "Read 138777 lines. Lines per second: 109410"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/9_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/9_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 161382 lines in 1.39207 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 161382 lines in 1.39207 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/10_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/10_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 1.47013 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 1.47013 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/10_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/10_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 289847 lines in 1.57917 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 289847 lines in 1.57917 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/11_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/11_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 1.30899 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 1.30899 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,float,str,str,str,str,str,float,str,str,str,str,int,str,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/11_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/cb/11_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 225184 lines in 1.2367 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 225184 lines in 1.2367 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/0_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/0_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.049123 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.049123 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,float,str,str,str,str,str,float,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/0_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/0_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 6615 lines in 0.046983 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 6615 lines in 0.046983 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/1_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/1_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.01079 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.01079 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,float,str,str,str,str,str,float,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/1_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/1_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 141 lines in 0.011585 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 141 lines in 0.011585 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Read 100 lines. Lines per second: 931.741</pre>"
      ],
      "text/plain": [
       "Read 100 lines. Lines per second: 931.741"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/2_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/2_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.108728 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.108728 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,float,float,float,str,float,str,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/2_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/2_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 12005 lines in 0.080942 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 12005 lines in 0.080942 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/3_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/3_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.039677 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.039677 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,float,float,float,str,float,str,str,float,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/3_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/3_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 3628 lines in 0.038964 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 3628 lines in 0.038964 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/4_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/4_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.086021 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.086021 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/4_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/4_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 11758 lines in 0.064408 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 11758 lines in 0.064408 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/5_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/5_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.051696 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.051696 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/5_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/5_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 6653 lines in 0.037901 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 6653 lines in 0.037901 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/6_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/6_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.10971 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.10971 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/6_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/6_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 17224 lines in 0.090287 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 17224 lines in 0.090287 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/7_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/7_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.012162 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.012162 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/7_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/7_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1460 lines in 0.018112 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1460 lines in 0.018112 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/8_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/8_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.198891 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.198891 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/8_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/8_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 25036 lines in 0.131243 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 25036 lines in 0.131243 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/9_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/9_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.2837 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.2837 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,float,float,float,str,float,str,str,float,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/9_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/9_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 33517 lines in 0.339655 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 33517 lines in 0.339655 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/10_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/10_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.094225 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.094225 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/10_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/10_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 13729 lines in 0.081328 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 13729 lines in 0.081328 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/11_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/11_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.166264 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.166264 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,float,str,str,str,str,str,float,str,str,str,str,int,str,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/11_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_temp/p1/11_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 24993 lines in 0.118993 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 24993 lines in 0.118993 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lst_of_frames = []\n",
    "for val in ['cb','p1']:\n",
    "    lst = []\n",
    "    for idx in range(12):\n",
    "        path = 'files/output/graph_temp/{}/{}_df.csv'.format(val, idx)\n",
    "        lst.append(SFrame(data=path))\n",
    "    lst_of_frames.append(lst)\n",
    "cb_sframes,p1_sframes = lst_of_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Load SFrames into graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create function to format SFrames for loading into SGraph\n",
    "\n",
    "#### Vertices: Person, Company, or Investor\n",
    "\n",
    "Node attributes: `__id`, `__node_type`, `name`\n",
    "\n",
    "#### Edges: Investment, Job\n",
    "\n",
    "Edge attributes: `__src_id`, `__dst_id`, `__edge_type`, `status`, {`__id`}, {`investment_type`,`raised_amount_usd`, `investor_count`, `is_lead_investor`, `lead_investor_count`}, {`job_type`, `title`}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def load_vertices(sframes, g):\n",
    "    \n",
    "    # For jobs dataframes\n",
    "    for idx in [4,5,6,8,10]:\n",
    "        frame_temp = sframes[idx][['person_uuid', 'person_name']].rename({'person_uuid':'__id', 'person_name':'name'})\n",
    "        frame_temp['__node_type'] = 'person'\n",
    "        frame_temp['p1_tag'] = 0\n",
    "        g = g.add_vertices(vertices=frame_temp, vid_field='__id')\n",
    "    \n",
    "    # For jobs and partner investments dataframes\n",
    "    for idx in [2,3,4,5,6,8,9,10]:\n",
    "        frame_temp = sframes[idx][['org_uuid', 'org_name', 'p1_tag']].rename({'org_uuid':'__id', 'org_name':'name'})\n",
    "        frame_temp['p1_tag'] = frame_temp['p1_tag'].apply(lambda x: 0 if (x==\"\" or x==0) else 1)\n",
    "        frame_temp['p1_tag'] = frame_temp['p1_tag'].astype(int)\n",
    "        frame_temp['__node_type'] = 'company'\n",
    "        g = g.add_vertices(vertices=frame_temp, vid_field='__id')\n",
    "    \n",
    "    # For investments dataframes\n",
    "    for idx in [2,3,7,9]:\n",
    "        frame_temp = sframes[idx][['investor_uuid', 'investor_name']].rename({'investor_uuid':'__id', 'investor_name':'name'})\n",
    "        frame_temp['__node_type'] = 'investor'\n",
    "        frame_temp['p1_tag'] = 0\n",
    "        g = g.add_vertices(vertices=frame_temp, vid_field='__id')\n",
    "    \n",
    "    # For partner investments dataframes\n",
    "    for idx in [3,7,9]:\n",
    "        frame_temp = sframes[idx][['partner_uuid', 'partner_name']].rename({'partner_uuid':'__id', 'partner_name':'name'})\n",
    "        frame_temp['__node_type'] = 'person'\n",
    "        frame_temp['p1_tag'] = 0\n",
    "        g = g.add_vertices(vertices=frame_temp, vid_field='__id')\n",
    "    \n",
    "    # Organizations\n",
    "    for idx in [0,1,11]:\n",
    "        # Create id field in SFrame\n",
    "        frame_temp = sframes[idx][['uuid', 'name', 'primary_role', 'p1_tag']].rename({'uuid':'__id', 'primary_role':'__node_type'})\n",
    "        frame_temp['p1_tag'] = frame_temp['p1_tag'].apply(lambda x: 0 if (x==\"\" or x==0) else 1)\n",
    "        frame_temp['p1_tag'] = frame_temp['p1_tag'].astype(int)\n",
    "        g = g.add_vertices(vertices=frame_temp, vid_field='__id')\n",
    "    \n",
    "    return g\n",
    "\n",
    "def find_p1_affiliations(p1_sframes):\n",
    "    frames = copy.deepcopy(p1_sframes)\n",
    "    \n",
    "    # Combine company and investor Pledge 1% dataframes\n",
    "    p1_affiliations = frames[0][['uuid']].append(frames[1][['uuid']])\n",
    "    \n",
    "    # Add edge connecting to Pledge 1% uuid\n",
    "    p1_affiliations['p1_uuid'] = 'fd9e2d10-a882-c6f4-737e-fd388d4ffd7c'\n",
    "    \n",
    "    # Create id, source, destination fields in SFrame\n",
    "    p1_affiliations = p1_affiliations.rename({'uuid':'src','p1_uuid':'dst'})\n",
    "    p1_affiliations['p1_tag'] = 1\n",
    "    \n",
    "    return p1_affiliations\n",
    "\n",
    "p1_aff = find_p1_affiliations(p1_sframes)\n",
    "\n",
    "def load_edges(sframes, g, p1_affiliations=[], include_edges=[2,3]):\n",
    "    \n",
    "    if type(p1_affiliations) == SFrame:\n",
    "        # P1 Companies: Company/Investor --> Pledge 1%\n",
    "        g = g.add_edges(edges=p1_affiliations, src_field='src', dst_field='dst')\n",
    "    \n",
    "    # Investments: Investor --> Company\n",
    "    # Create id, source, destination fields in SFrame\n",
    "    frame_temp = sframes[2][['investment_uuid','investor_uuid','org_uuid','investment_type','raised_amount_usd','investor_count','is_lead_investor','lead_investor_count']].rename({'investment_uuid':'__id','investor_uuid':'src','org_uuid':'dst'})\n",
    "    frame_temp['__edge_type'] = 'investment'\n",
    "    frame_temp['status'] = 'primary'\n",
    "    g = g.add_edges(edges=frame_temp, src_field='src', dst_field='dst')\n",
    "    \n",
    "    # Partner Investments, Investments: Person --> Company\n",
    "    # Create id, source, destination fields in SFrame\n",
    "    frame_temp = sframes[3][['investment_uuid','partner_uuid','org_uuid','investment_type','raised_amount_usd','investor_count']].rename({'investment_uuid':'__id','partner_uuid':'src','org_uuid':'dst'})\n",
    "    frame_temp['__edge_type'] = 'investment'\n",
    "    frame_temp['status'] = 'primary'\n",
    "    g = g.add_edges(edges=frame_temp, src_field='src', dst_field='dst')\n",
    "    \n",
    "    # Partner Investments, Investments: Investor --> Company\n",
    "    # Create id, source, destination fields in SFrame\n",
    "    frame_temp = sframes[3][['investor_uuid','org_uuid','investment_type','investor_count']].rename({'investor_uuid':'src','org_uuid':'dst'})\n",
    "    frame_temp['__edge_type'] = 'investment'\n",
    "    frame_temp['status'] = 'secondary'\n",
    "    # Secondary relationships\n",
    "    if 2 in include_edges:\n",
    "        g = g.add_edges(edges=frame_temp, src_field='src', dst_field='dst')\n",
    "    \n",
    "    # Partner Investments, Jobs: Person --> Company\n",
    "    # Create id, source, destination fields in SFrame\n",
    "    frame_temp = sframes[7][['partner_uuid','investor_uuid']].rename({'partner_uuid':'src','investor_uuid':'dst'})\n",
    "    frame_temp['__edge_type'] = 'job'\n",
    "    frame_temp['status'] = 'secondary'\n",
    "    # Secondary relationships\n",
    "    if 2 in include_edges:\n",
    "        g = g.add_edges(edges=frame_temp, src_field='src', dst_field='dst')    \n",
    "    \n",
    "    # Other Partner Investments, Investments: Person --> Company\n",
    "    # Create id, source, destination fields in SFrame\n",
    "    frame_temp = sframes[9][['investment_uuid','partner_uuid','org_uuid','investment_type','raised_amount_usd','investor_count']].rename({'investment_uuid':'__id','partner_uuid':'src','org_uuid':'dst'})\n",
    "    frame_temp['__edge_type'] = 'investment'\n",
    "    frame_temp['status'] = 'tertiary'\n",
    "    # Tertiary relationships\n",
    "    if 3 in include_edges:\n",
    "        g = g.add_edges(edges=frame_temp, src_field='src', dst_field='dst')\n",
    "    \n",
    "    # Jobs: Person --> Company\n",
    "    for idx in [4,5,6,8,10]:\n",
    "        # Create id, source, destination fields in SFrame\n",
    "        frame_temp = sframes[idx][['job_uuid','person_uuid','org_uuid','job_type','title']].rename({'job_uuid':'__id','person_uuid':'src','org_uuid':'dst'})\n",
    "        frame_temp['__edge_type'] = 'job'\n",
    "        \n",
    "        # Current jobs\n",
    "        if idx == 4:\n",
    "            frame_temp['status'] = 'primary'\n",
    "            g = g.add_edges(edges=frame_temp, src_field='src', dst_field='dst')\n",
    "            continue\n",
    "        \n",
    "        # Secondary relationships\n",
    "        if 2 in include_edges:\n",
    "            \n",
    "            # Former jobs | Former new jobs | Current old jobs \n",
    "            if idx in [5,6,10]:\n",
    "                frame_temp['status'] = 'secondary'\n",
    "                g = g.add_edges(edges=frame_temp, src_field='src', dst_field='dst')\n",
    "                continue\n",
    "        \n",
    "        # Tertiary relationships\n",
    "        if 3 in include_edges:\n",
    "            \n",
    "            # Other partners at firm\n",
    "            if idx == 8:\n",
    "                frame_temp['status'] = 'tertiary'\n",
    "                g = g.add_edges(edges=frame_temp, src_field='src', dst_field='dst')\n",
    "                continue\n",
    "\n",
    "    return g\n",
    "\n",
    "cb = load_edges(cb_sframes, load_vertices(cb_sframes,SGraph()), p1_aff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_edges2(sframes, g, p1_affiliations=[], include_edges=[2,3], reverse=False):\n",
    "    # Since it is a directed graph, need to include option for reverse direction\n",
    "    # Forward\n",
    "    source = 'src'\n",
    "    destination = 'dst'\n",
    "    # Reverse\n",
    "    if reverse:\n",
    "        source = 'dst'\n",
    "        destination = 'src'\n",
    "    if type(p1_affiliations) == SFrame:\n",
    "        # P1 Companies: Company/Investor --> Pledge 1%\n",
    "        g = g.add_edges(edges=p1_affiliations, src_field=source, dst_field=destination)\n",
    "    # Investments: Investor --> Company\n",
    "    # Create id, source, destination fields in SFrame\n",
    "    frame_temp = sframes[2][['investment_uuid','investor_uuid','org_uuid','investment_type','raised_amount_usd','investor_count','is_lead_investor','lead_investor_count']].rename({'investment_uuid':'__id','investor_uuid':'src','org_uuid':'dst'})\n",
    "    frame_temp['__edge_type'] = 'investment'\n",
    "    frame_temp['status'] = 'primary'\n",
    "    g = g.add_edges(edges=frame_temp, src_field=source, dst_field=destination)\n",
    "    # Partner Investments, Investments: Person --> Company\n",
    "    # Create id, source, destination fields in SFrame\n",
    "    frame_temp = sframes[3][['investment_uuid','partner_uuid','org_uuid','investment_type','raised_amount_usd','investor_count']].rename({'investment_uuid':'__id','partner_uuid':'src','org_uuid':'dst'})\n",
    "    frame_temp['__edge_type'] = 'investment'\n",
    "    frame_temp['status'] = 'primary'\n",
    "    g = g.add_edges(edges=frame_temp, src_field=source, dst_field=destination)\n",
    "    # Partner Investments, Investments: Investor --> Company\n",
    "    # Create id, source, destination fields in SFrame\n",
    "    frame_temp = sframes[3][['investor_uuid','org_uuid','investment_type','investor_count']].rename({'investor_uuid':'src','org_uuid':'dst'})\n",
    "    frame_temp['__edge_type'] = 'investment'\n",
    "    frame_temp['status'] = 'secondary'\n",
    "    # Secondary relationships, skip if not specified at input\n",
    "    if 2 in include_edges:\n",
    "        g = g.add_edges(edges=frame_temp, src_field=source, dst_field=destination)\n",
    "    # Partner Investments, Jobs: Person --> Company\n",
    "    # Create id, source, destination fields in SFrame\n",
    "    frame_temp = sframes[7][['partner_uuid','investor_uuid']].rename({'partner_uuid':'src','investor_uuid':'dst'})\n",
    "    frame_temp['__edge_type'] = 'job'\n",
    "    frame_temp['status'] = 'secondary'\n",
    "    # Secondary relationships, skip if not specified at input\n",
    "    if 2 in include_edges:\n",
    "        g = g.add_edges(edges=frame_temp, src_field=source, dst_field=destination)    \n",
    "    # Other Partner Investments, Investments: Person --> Company\n",
    "    # Create id, source, destination fields in SFrame\n",
    "    frame_temp = sframes[9][['investment_uuid','partner_uuid','org_uuid','investment_type','raised_amount_usd','investor_count']].rename({'investment_uuid':'__id','partner_uuid':'src','org_uuid':'dst'})\n",
    "    frame_temp['__edge_type'] = 'investment'\n",
    "    frame_temp['status'] = 'tertiary'\n",
    "    # Tertiary relationships, skip if not specified at input\n",
    "    if 3 in include_edges:\n",
    "        g = g.add_edges(edges=frame_temp, src_field=source, dst_field=destination)\n",
    "    # Jobs: Person --> Company\n",
    "    for idx in [4,5,6,8,10]:\n",
    "        # Create id, source, destination fields in SFrame\n",
    "        frame_temp = sframes[idx][['job_uuid','person_uuid','org_uuid','job_type','title']].rename({'job_uuid':'__id','person_uuid':'src','org_uuid':'dst'})\n",
    "        frame_temp['__edge_type'] = 'job'\n",
    "        # Current jobs\n",
    "        if idx == 4:\n",
    "            frame_temp['status'] = 'primary'\n",
    "            g = g.add_edges(edges=frame_temp, src_field=source, dst_field=destination)\n",
    "            continue\n",
    "        # Secondary relationships, skip if not specified at input\n",
    "        if 2 in include_edges:\n",
    "            # Former jobs | Former new jobs | Current old jobs \n",
    "            if idx in [5,6,10]:\n",
    "                frame_temp['status'] = 'secondary'\n",
    "                g = g.add_edges(edges=frame_temp, src_field=source, dst_field=destination)\n",
    "                continue\n",
    "        # Tertiary relationships, skip if not specified at input\n",
    "        if 3 in include_edges:\n",
    "            # Other partners at firm\n",
    "            if idx == 8:\n",
    "                frame_temp['status'] = 'tertiary'\n",
    "                g = g.add_edges(edges=frame_temp, src_field=source, dst_field=destination)\n",
    "                continue\n",
    "    return g\n",
    "# Load in crunchbase with relationships defined above (primary, secondary, tertiary)\n",
    "cb = load_edges2(cb_sframes, load_vertices(cb_sframes,SGraph()), p1_affiliations=[], include_edges=[2,3], reverse=False)\n",
    "cb = load_edges2(cb_sframes, cb, p1_affiliations=[], include_edges=[2,3], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicate edges\n",
    "\n",
    "From: <a href='https://github.com/turi-code/how-to/blob/master/remove_duplicate_edges.py'>Remove duplicate edges from SGraph</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove duplicates from Crunchbase graph\n",
      "\n",
      "Node change: 1,290,346 --> 1,290,346\n",
      "Edge change: 4,170,144 --> 4,170,144\n",
      "\n",
      "PRIMARY Edge change: 1,876,400 --> 1,876,400\n",
      "SECONDARY Edge change: 1,328,800 --> 1,328,800\n",
      "TERTIARY Edge change: 964,944 --> 964,944\n"
     ]
    }
   ],
   "source": [
    "# Get list of edge fields\n",
    "graph_edge_fields = cb.get_edge_fields()\n",
    "\n",
    "# Create temporary edge attribute that you'll use in aggregate function\n",
    "cb.edges['combined'] = cb.edges['__id']+','+cb.edges['status']+','+cb.edges['__src_id']+','+cb.edges['__dst_id']\n",
    "\n",
    "# Before comparison\n",
    "before = cb.summary()\n",
    "before_pri = cb.get_edges(fields={'status':'primary'}).shape[0]\n",
    "before_sec = cb.get_edges(fields={'status':'secondary'}).shape[0]\n",
    "before_ter = cb.get_edges(fields={'status':'tertiary'}).shape[0]\n",
    "\n",
    "# Select one value of duplicated rows th\n",
    "cb = SGraph(cb.vertices, cb.edges.groupby(graph_edge_fields, {'combined': aggregate.SELECT_ONE('combined')}))\n",
    "\n",
    "# After comparison\n",
    "after = cb.summary()\n",
    "after_pri = cb.get_edges(fields={'status':'primary'}).shape[0]\n",
    "after_sec = cb.get_edges(fields={'status':'secondary'}).shape[0]\n",
    "after_ter = cb.get_edges(fields={'status':'tertiary'}).shape[0]\n",
    "\n",
    "# Output\n",
    "print('Remove duplicates from Crunchbase graph')\n",
    "print('\\nNode change: {:,} --> {:,}'.format(before['num_vertices'], after['num_vertices']))\n",
    "print('Edge change: {:,} --> {:,}'.format(before['num_edges'], after['num_edges']))\n",
    "print('\\nPRIMARY Edge change: {:,} --> {:,}'.format(before_pri,after_pri))\n",
    "print('SECONDARY Edge change: {:,} --> {:,}'.format(before_sec,after_sec))\n",
    "print('TERTIARY Edge change: {:,} --> {:,}'.format(before_ter,after_ter))\n",
    "\n",
    "del cb.edges['combined']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Reduce size of dataset by limiting degrees of freedom from Pledge 1%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce the CB dataset\n",
    "\n",
    "Retrieve the graph neighborhood around a set of vertices, ignoring edge directions.\n",
    "\n",
    "<a href='https://apple.github.io/turicreate/docs/api/generated/turicreate.SGraph.get_neighborhood.html'>turicreate.SGraph.get_neighborhood</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Radius of the neighborhood: 3 degrees of separation from Pledge 1% uuid\n",
      "Reduction in nodes: 100.00%\n",
      "Reduction in edges: 100.00%\n",
      "\n",
      "Node change: 1,290,346 --> 44\n",
      "Edge change: 4,170,144 --> 212\n"
     ]
    }
   ],
   "source": [
    "# Define radius for calculating degrees of separation away from Pledge 1%\n",
    "rad = 3\n",
    "\n",
    "# Create subgraph\n",
    "cb_smol = cb.get_neighborhood(ids='fd9e2d10-a882-c6f4-737e-fd388d4ffd7c', radius=rad, full_subgraph=True)\n",
    "\n",
    "# Save dictionaries which store info about graph\n",
    "before = cb.summary() # Full graph\n",
    "after = cb_smol.summary() # Subgraph\n",
    "\n",
    "# Output\n",
    "print('Radius of the neighborhood: {} degrees of separation from Pledge 1% uuid'.format(rad))\n",
    "print('Reduction in nodes: {:.2f}%'.format((1-(after['num_vertices']/before['num_vertices']))*100))\n",
    "print('Reduction in edges: {:.2f}%'.format((1-(after['num_edges']/before['num_edges']))*100))\n",
    "print('\\nNode change: {:,} --> {:,}'.format(before['num_vertices'], after['num_vertices']))\n",
    "print('Edge change: {:,} --> {:,}'.format(before['num_edges'], after['num_edges']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Create random sample of non-P1 organizations, equal to number of P1 organizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve list of company vertices that can be sampled from in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model vertices: 13,512\n"
     ]
    }
   ],
   "source": [
    "# Get subgraph vertices to sample from\n",
    "cb_smol_ver = cb_smol.get_vertices()\n",
    "\n",
    "# Append investors + companies together\n",
    "cb_smol_ver_NEW = cb_smol_ver[cb_smol_ver['__node_type']=='investor']\n",
    "cb_smol_ver_NEW = cb_smol_ver_NEW.append(cb_smol_ver[cb_smol_ver['__node_type']=='company'])\n",
    "\n",
    "# Grab actual P1 companies, using output of find_p1_affiliations function\n",
    "pos_labels = pd.DataFrame(p1_aff)['src'].to_list()\n",
    "\n",
    "# Sample equal size of P1 companies from subgraph\n",
    "neg_labels = pd.DataFrame(cb_smol_ver_NEW).sample(len(pos_labels), replace=False).__id.to_list()\n",
    "\n",
    "# List of IDs to put into subgraph calculation\n",
    "model_labels = pos_labels + neg_labels\n",
    "\n",
    "# Don't forget Pledge 1%!\n",
    "#model_labels.append('fd9e2d10-a882-c6f4-737e-fd388d4ffd7c')\n",
    "\n",
    "print('Number of model vertices: {:,}'.format(len(model_labels)))\n",
    "\n",
    "# NOTE: There are vertices with \"None\" listed as their node_type in the 4deg subgraph, someone investigate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model vertices: 13,512\n"
     ]
    }
   ],
   "source": [
    "# Get subgraph vertices to sample from\n",
    "cb_smol_ver = cb.get_vertices()\n",
    "\n",
    "# Append investors + companies together\n",
    "cb_smol_ver_NEW = cb_smol_ver[cb_smol_ver['__node_type']=='investor']\n",
    "cb_smol_ver_NEW = cb_smol_ver_NEW.append(cb_smol_ver[cb_smol_ver['__node_type']=='company'])\n",
    "\n",
    "# Grab actual P1 companies, using output of find_p1_affiliations function\n",
    "pos_labels = pd.DataFrame(p1_aff)['src'].to_list()\n",
    "\n",
    "# Sample equal size of P1 companies from subgraph\n",
    "neg_labels = pd.DataFrame(cb_smol_ver_NEW).sample(len(pos_labels), replace=False).__id.to_list()\n",
    "\n",
    "# List of IDs to put into subgraph calculation\n",
    "model_labels = pos_labels + neg_labels\n",
    "\n",
    "# Don't forget Pledge 1%!\n",
    "#model_labels.append('fd9e2d10-a882-c6f4-737e-fd388d4ffd7c')\n",
    "\n",
    "print('Number of model vertices: {:,}'.format(len(model_labels)))\n",
    "\n",
    "# NOTE: There are vertices with \"None\" listed as their node_type in the 4deg subgraph, someone investigate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Load in updated dataframes with sample uuids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Create subgraph within subgraph (No?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define radius for calculating degrees of separation away from model vertices\n",
    "# rad = 2\n",
    "\n",
    "# # Create subgraph\n",
    "# model = cb_d4_p1.get_neighborhood(ids=model_labels, radius=rad, full_subgraph=True)\n",
    "\n",
    "# # Save dictionaries which store info about graph\n",
    "# model_summary = model.summary() # Full graph\n",
    "\n",
    "# print('Radius of the neighborhood: {} degrees of separation from model uuids'.format(rad))\n",
    "# print('Reduction in nodes: {:.2f}%'.format((1-(model_summary['num_vertices']/cb_d4_p1_summary['num_vertices']))*100))\n",
    "# print('Reduction in edges: {:.2f}%'.format((1-(model_summary['num_edges']/cb_d4_p1_summary['num_edges']))*100))\n",
    "# print('\\nNode change: {:,} --> {:,}'.format(cb_d4_p1_summary['num_vertices'], model_summary['num_vertices']))\n",
    "# print('Edge change: {:,} --> {:,}'.format(cb_d4_p1_summary['num_edges'], model_summary['num_edges']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-do earlier steps to construct new graph network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AS OF SEPTEMBER 08, 2020:\n",
      "\n",
      "CaLcUlAtInG... FORMER NEW JOB FILTER\n",
      "CaLcUlAtInG... PARTNER INVESTMENT JOB FILTER\n",
      "CaLcUlAtInG... OTHER FIRM PARTNER JOBS & INVESTMENTS FILTER\n",
      "CaLcUlAtInG... CURRENT OLD JOB FILTER\n",
      "CaLcUlAtInG... EXTRA ORGANIZATION NODES\n",
      "\n",
      "Crunchbase Neighborhood\n",
      "NODES | OUTPUT FRAME 0/CB_companies (825393, 16)\n",
      "NODES | OUTPUT FRAME 1/CB_investors (31499, 16)\n",
      "NODES&EDGES | OUTPUT FRAME 2/CB_investments (453058, 17)\n",
      "NODES&EDGES | OUTPUT FRAME 3/CB_investment_partners (89926, 18)\n",
      "NODES&EDGES | OUTPUT FRAME 4/CB_jobs (395270, 12)\n",
      "NODES&EDGES | OUTPUT FRAME 5/CB_jobs_former (182483, 12)\n",
      "NODES&EDGES | OUTPUT FRAME 6/CB_jobs_former_new (483629, 12)\n",
      "NODES&EDGES | OUTPUT FRAME 7/CB_jobs_partner (11771, 5)\n",
      "NODES&EDGES | OUTPUT FRAME 8/CB_jobs_other_partners (434370, 12)\n",
      "NODES&EDGES | OUTPUT FRAME 9/CB_invest_other_partners (161382, 18)\n",
      "NODES&EDGES | OUTPUT FRAME 10/CB_jobs_current_old (289847, 12)\n",
      "NODES | OUTPUT FRAME 11/CB_extra_org_nodes (225184, 17)\n",
      "\n",
      "Model Neighborhood\n",
      "NODES | OUTPUT FRAME 0/model_companies (12693, 16)\n",
      "NODES | OUTPUT FRAME 1/model_investors (361, 16)\n",
      "NODES&EDGES | OUTPUT FRAME 2/model_investments (15041, 17)\n",
      "NODES&EDGES | OUTPUT FRAME 3/model_investment_partners (4261, 18)\n",
      "NODES&EDGES | OUTPUT FRAME 4/model_jobs (14415, 12)\n",
      "NODES&EDGES | OUTPUT FRAME 5/model_jobs_former (7785, 12)\n",
      "NODES&EDGES | OUTPUT FRAME 6/model_jobs_former_new (20926, 12)\n",
      "NODES&EDGES | OUTPUT FRAME 7/model_jobs_partner (1759, 5)\n",
      "NODES&EDGES | OUTPUT FRAME 8/model_jobs_other_partners (30604, 12)\n",
      "NODES&EDGES | OUTPUT FRAME 9/model_invest_other_partners (37166, 18)\n",
      "NODES&EDGES | OUTPUT FRAME 10/model_jobs_current_old (16131, 12)\n",
      "NODES | OUTPUT FRAME 11/model_extra_org_nodes (29473, 17)\n"
     ]
    }
   ],
   "source": [
    "cb_frames,model_frames = network_by_date(date, df, jobs, invest, invest_prtnr, model_uuids=model_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Save filter dataframes as separate CSVs, and then load in as SFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save filtered dataframes as separate CSVs & load in nodes, edges as SFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SAVED TO CSV', 'files/output/graph_model/model/0_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_model/model/1_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_model/model/2_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_model/model/3_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_model/model/4_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_model/model/5_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_model/model/6_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_model/model/7_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_model/model/8_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_model/model/9_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_model/model/10_df.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_model/model/11_df.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/0_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/0_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.142435 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.142435 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,float,str,str,str,str,str,float,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/0_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/0_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 12693 lines in 0.082513 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 12693 lines in 0.082513 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/1_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/1_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.013526 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.013526 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,float,str,str,str,str,str,float,str,str,str,str,int,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/1_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/1_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 361 lines in 0.009378 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 361 lines in 0.009378 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/2_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/2_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.294658 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.294658 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,float,float,float,str,float,str,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/2_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/2_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 15041 lines in 0.164237 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 15041 lines in 0.164237 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/3_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/3_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.07888 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.07888 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,float,float,float,str,float,str,str,float,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/3_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/3_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 4261 lines in 0.057172 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 4261 lines in 0.057172 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/4_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/4_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.099752 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.099752 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/4_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/4_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 14415 lines in 0.100137 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 14415 lines in 0.100137 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/5_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/5_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.076836 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.076836 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/5_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/5_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 7785 lines in 0.075619 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 7785 lines in 0.075619 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/6_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/6_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.222316 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.222316 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/6_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/6_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 20926 lines in 0.136707 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 20926 lines in 0.136707 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/7_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/7_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.014986 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.014986 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/7_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/7_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 1759 lines in 0.014883 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 1759 lines in 0.014883 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/8_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/8_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.193164 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.193164 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/8_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/8_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 30604 lines in 0.186107 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 30604 lines in 0.186107 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/9_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/9_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.48421 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.48421 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,float,float,float,str,float,str,str,float,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/9_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/9_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 37166 lines in 0.617885 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 37166 lines in 0.617885 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/10_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/10_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.107147 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.107147 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,float,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/10_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/10_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 16131 lines in 0.099725 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 16131 lines in 0.099725 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/11_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/11_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.315677 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.315677 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,float,str,str,str,str,str,float,str,str,str,str,int,str,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/11_df.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/sanjayelangovan/Desktop/School/Grad School/Term 3/coursework/Projects/final_project/crunchbase-p1-machine-learning/files/output/graph_model/model/11_df.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 29473 lines in 0.247586 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 29473 lines in 0.247586 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx, frame in enumerate(model_frames):\n",
    "    path = 'files/output/graph_model/model/{}_df.csv'.format(idx)\n",
    "    print('SAVED TO CSV', path)\n",
    "    frame.to_csv(path, index=False)\n",
    "\n",
    "model_sframes = []\n",
    "for idx in range(12):\n",
    "    path = 'files/output/graph_model/model/{}_df.csv'.format(idx)\n",
    "    model_sframes.append(SFrame(data=path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Load SFrames into graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove duplicates from model graph\n",
      "\n",
      "Node change: 77,199 --> 77,199\n",
      "Edge change: 152,349 --> 143,177\n",
      "\n",
      "PRIMARY Edge change: 33,717 --> 33,707\n",
      "SECONDARY Edge change: 50,862 --> 43,135\n",
      "TERTIARY Edge change: 67,770 --> 66,335\n"
     ]
    }
   ],
   "source": [
    "# Don't include Pledge 1% \n",
    "model_g = load_edges(model_sframes, load_vertices(model_sframes,SGraph()))\n",
    "\n",
    "graph_edge_fields = model_g.get_edge_fields()\n",
    "model_g.edges['combined'] = model_g.edges['__id']+','+model_g.edges['status']+','+model_g.edges['__src_id']+','+model_g.edges['__dst_id']\n",
    "\n",
    "# Before comparison\n",
    "before = model_g.summary()\n",
    "before_pri = model_g.get_edges(fields={'status':'primary'}).shape[0]\n",
    "before_sec = model_g.get_edges(fields={'status':'secondary'}).shape[0]\n",
    "before_ter = model_g.get_edges(fields={'status':'tertiary'}).shape[0]\n",
    "\n",
    "# Remove it by the 'status' field, similar start and ending node\n",
    "model_g = SGraph(model_g.vertices, model_g.edges.groupby(graph_edge_fields, {'combined': aggregate.SELECT_ONE('combined')}))\n",
    "\n",
    "# After comparison\n",
    "after = model_g.summary()\n",
    "after_pri = model_g.get_edges(fields={'status':'primary'}).shape[0]\n",
    "after_sec = model_g.get_edges(fields={'status':'secondary'}).shape[0]\n",
    "after_ter = model_g.get_edges(fields={'status':'tertiary'}).shape[0]\n",
    "\n",
    "# Output\n",
    "print('Remove duplicates from model graph')\n",
    "print('\\nNode change: {:,} --> {:,}'.format(before['num_vertices'], after['num_vertices']))\n",
    "print('Edge change: {:,} --> {:,}'.format(before['num_edges'], after['num_edges']))\n",
    "print('\\nPRIMARY Edge change: {:,} --> {:,}'.format(before_pri,after_pri))\n",
    "print('SECONDARY Edge change: {:,} --> {:,}'.format(before_sec,after_sec))\n",
    "print('TERTIARY Edge change: {:,} --> {:,}'.format(before_ter,after_ter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Graph feature calculations, save to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pagerank\n",
    "\n",
    "The pagerank.create() method computes the pagerank for each vertex and returns a PagerankModel. The pagerank value indicates the centrality of each node in the graph.\n",
    "\n",
    "Compute the PageRank for each vertex in the graph. Return a model object with total PageRank as well as the PageRank value for each vertex in the graph.\n",
    "\n",
    "<a href='https://apple.github.io/turicreate/docs/api/generated/turicreate.pagerank.create.html#turicreate.pagerank.create'>turicreate.pagerank.create</a> | <a href='https://apple.github.io/turicreate/docs/api/generated/turicreate.SGraph.get_vertices.html#turicreate.SGraph.get_vertices'>turicreate.SGraph.get_vertices</a>\n",
    "\n",
    "Follow steps here? <a href='http://snap.stanford.edu/mlg2013/submissions/mlg2013_submission_7.pdf'>Article</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Google\n",
      "2. Microsoft\n",
      "3. IBM\n",
      "4. Yahoo\n",
      "5. Requisite Technology\n",
      "6. Puppet\n",
      "7. O3b Networks\n",
      "8. SAP\n",
      "9. VMware\n",
      "10. GeoCities\n",
      "11. Deloitte\n",
      "12. SendFriend\n",
      "13. CVC Capital Partners\n",
      "14. Apttus\n",
      "15. Salesforce\n",
      "16. Facebook\n",
      "17. KPMG\n",
      "18. Cisco\n",
      "19. Warburg Pincus\n",
      "20. E-contenta\n",
      "21. Kohlberg Kravis Roberts\n",
      "22. R3\n",
      "23. Amazon\n",
      "24. Intel\n",
      "25. Flexport\n",
      "26. Accenture\n",
      "27. Investcorp\n",
      "28. The Carlyle Group\n",
      "29. Box\n",
      "30. HarbourVest Partners\n",
      "31. The Boston Consulting Group\n",
      "32. Techstars\n",
      "33. Oracle\n",
      "34. Dropbox\n",
      "35. KaiOS Technologies\n",
      "36. Xevo\n",
      "37. General Atlantic\n",
      "38. SolarCity\n",
      "39. DocuSign\n",
      "40. Unacademy\n",
      "41. Proteus Digital Health\n",
      "42. Adams Street Partners\n",
      "43. Samsung Electronics\n",
      "44. Twilio\n",
      "45. Mirantis\n",
      "46. SalesLoft\n",
      "47. AppNexus\n",
      "48. Demandbase\n",
      "49. Hello Heart\n",
      "50. XANT.ai\n",
      "<class 'turicreate.data_structures.sframe.SFrame'>\n",
      "('\\nSAVED TO CSV', 'files/output/graph_model/model/pagerank_df_deg3.csv')\n"
     ]
    }
   ],
   "source": [
    "pr = pagerank.create(model_g, verbose=False)\n",
    "pr_out = pr['pagerank']\n",
    "pr_out=pr_out.sort('pagerank', ascending=False)\n",
    "for idx, uuid in enumerate(pr_out['__id']):\n",
    "    if idx+1 < 51:\n",
    "        print('{}. {}'.format(idx+1, model_g.get_vertices(ids=uuid)['name'][0]))\n",
    "    else:\n",
    "        break\n",
    "\n",
    "pagerank_out = pd.DataFrame(pr_out)\n",
    "pagerank_out = pagerank_out[pagerank_out['__id'].isin(model_labels)].reset_index(drop=True)\n",
    "\n",
    "path = 'files/output/graph_model/model/pagerank_df_deg3.csv'\n",
    "pagerank_out.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3> Degrees </H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model computes the inbound, outbound, and total degree for each vector.\n",
    "https://apple.github.io/turicreate/docs/api/turicreate.toolkits.graph_analytics.html#shortest-path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SAVED TO CSV', 'files/output/graph_model/model/in_degree.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_model/model/out_degree.csv')\n",
      "('SAVED TO CSV', 'files/output/graph_model/model/total_degree.csv')\n"
     ]
    }
   ],
   "source": [
    "from turicreate import degree_counting\n",
    "deg = degree_counting.create(model_g)\n",
    "deg_graph = deg['graph'] # a new SGraph with degree data attached to each vertex\n",
    "in_degree = pd.DataFrame(deg_graph.vertices[['__id', 'in_degree']])\n",
    "out_degree = pd.DataFrame(deg_graph.vertices[['__id', 'out_degree']])\n",
    "total_degree = pd.DataFrame(deg_graph.vertices[['__id','total_degree']])\n",
    "\n",
    "path = 'files/output/graph_model/model/in_degree.csv'\n",
    "print ('SAVED TO CSV', path)\n",
    "in_degree.to_csv(path, index=False)\n",
    "\n",
    "path = 'files/output/graph_model/model/out_degree.csv'\n",
    "print ('SAVED TO CSV', path)\n",
    "out_degree.to_csv(path, index=False)\n",
    "\n",
    "path = 'files/output/graph_model/model/total_degree.csv'\n",
    "print ('SAVED TO CSV', path)\n",
    "total_degree.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Triangle Counting </h3>\n",
    "\n",
    "Computes the number of triangles each vertex belongs to. \n",
    "https://apple.github.io/turicreate/docs/api/generated/turicreate.triangle_counting.create.html#turicreate.triangle_counting.create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Initializing vertex ids.</pre>"
      ],
      "text/plain": [
       "Initializing vertex ids."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Removing duplicate (bidirectional) edges.</pre>"
      ],
      "text/plain": [
       "Removing duplicate (bidirectional) edges."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Counting triangles...</pre>"
      ],
      "text/plain": [
       "Counting triangles..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished in 3.48588 secs.</pre>"
      ],
      "text/plain": [
       "Finished in 3.48588 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Total triangles in the graph : 16804</pre>"
      ],
      "text/plain": [
       "Total triangles in the graph : 16804"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SAVED TO CSV', 'files/output/graph_model/model/triangle_count.csv')\n"
     ]
    }
   ],
   "source": [
    "from turicreate import triangle_counting\n",
    "tc = triangle_counting.create(model_g)\n",
    "triangle_count = pd.DataFrame(tc['triangle_count'])\n",
    "\n",
    "path = 'files/output/graph_model/model/triangle_count.csv'\n",
    "print ('SAVED TO CSV', path)\n",
    "triangle_count.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>K-Core Decomposition</h3>\n",
    "\n",
    "This method recursively removes vertices from the graph with degree less than k. The value of K at which a vertex is removed is its core ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Finish computing core 0\t Vertices left: 98654</pre>"
      ],
      "text/plain": [
       "Finish computing core 0\t Vertices left: 98654"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finish computing core 1\t Vertices left: 56391</pre>"
      ],
      "text/plain": [
       "Finish computing core 1\t Vertices left: 56391"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finish computing core 2\t Vertices left: 43951</pre>"
      ],
      "text/plain": [
       "Finish computing core 2\t Vertices left: 43951"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finish computing core 3\t Vertices left: 18507</pre>"
      ],
      "text/plain": [
       "Finish computing core 3\t Vertices left: 18507"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finish computing core 4\t Vertices left: 13426</pre>"
      ],
      "text/plain": [
       "Finish computing core 4\t Vertices left: 13426"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finish computing core 5\t Vertices left: 10320</pre>"
      ],
      "text/plain": [
       "Finish computing core 5\t Vertices left: 10320"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finish computing core 6\t Vertices left: 8130</pre>"
      ],
      "text/plain": [
       "Finish computing core 6\t Vertices left: 8130"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finish computing core 7\t Vertices left: 6805</pre>"
      ],
      "text/plain": [
       "Finish computing core 7\t Vertices left: 6805"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finish computing core 8\t Vertices left: 6084</pre>"
      ],
      "text/plain": [
       "Finish computing core 8\t Vertices left: 6084"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finish computing core 9\t Vertices left: 5356</pre>"
      ],
      "text/plain": [
       "Finish computing core 9\t Vertices left: 5356"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SAVED TO CSV', 'files/output/graph_model/model/kcore.csv')\n"
     ]
    }
   ],
   "source": [
    "from turicreate import kcore\n",
    "kc = kcore.create(model_g)\n",
    "kcore = pd.DataFrame(kc['core_id'])\n",
    "\n",
    "path = 'files/output/graph_model/model/kcore.csv'\n",
    "print ('SAVED TO CSV', path)\n",
    "kcore.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Distance from Pledge 1%</h3>\n",
    "\n",
    "This feature measures the distance from Pledge 1% itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turicreate import load_sgraph\n",
    "from turicreate import shortest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Taking only the values which have a P1 tag\n",
    "p1_tag = model_g.vertices[model_g.vertices['p1_tag']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 P1 companies have been checked.\n",
      "500 P1 companies have been checked.\n",
      "1000 P1 companies have been checked.\n",
      "1500 P1 companies have been checked.\n",
      "2000 P1 companies have been checked.\n",
      "2500 P1 companies have been checked.\n",
      "3000 P1 companies have been checked.\n",
      "3500 P1 companies have been checked.\n",
      "4000 P1 companies have been checked.\n",
      "4500 P1 companies have been checked.\n",
      "5000 P1 companies have been checked.\n",
      "5500 P1 companies have been checked.\n",
      "6000 P1 companies have been checked.\n",
      "6500 P1 companies have been checked.\n"
     ]
    }
   ],
   "source": [
    "from turicreate import SArray\n",
    "\n",
    "initial_check = 0\n",
    "df1 = pd.DataFrame(p1_tag['__id'])\n",
    "\n",
    "for i in p1_tag['__id']:\n",
    "    sp = shortest_path.create(model_g, source_vid=i, verbose = False)\n",
    "    a = sp['distance']\n",
    "    \n",
    "    if initial_check == 0:\n",
    "        distances = a\n",
    "        initial_check = 1\n",
    "        \n",
    "    else:\n",
    "        distances['distance'] = np.where(a['distance'] < distances['distance'], a['distance'], distances['distance'])  #create new column in df1 to check if prices match\n",
    "\n",
    "    if (df1[df1[0]==i].index.values % 500 == 0):\n",
    "        print (str(int(df1[df1[0]==i].index.values)) + \" P1 companies have been checked.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SAVED TO CSV', 'files/output/graph_model/model/shortest_distance_to_p1_company.csv')\n"
     ]
    }
   ],
   "source": [
    "distances2 = pd.DataFrame(distances)\n",
    "path = 'files/output/graph_model/model/shortest_distance_to_p1_company.csv'\n",
    "print ('SAVED TO CSV', path)\n",
    "distances2.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Running the same analysis but for the entire CB Network </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_tag2 = model_g.vertices[model_g.vertices['p1_tag']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turicreate import SArray\n",
    "\n",
    "initial_check = 0\n",
    "df1 = pd.DataFrame(p1_tag2['__id'])\n",
    "\n",
    "for i in p1_tag2['__id']:\n",
    "    sp = shortest_path.create(cb, source_vid=i, verbose = False)\n",
    "    a = sp['distance']\n",
    "    \n",
    "    if initial_check == 0:\n",
    "        distances2 = a\n",
    "        initial_check = 1\n",
    "        \n",
    "    else:\n",
    "        distances2['distance'] = np.where(a['distance'] < distances2['distance'], a['distance'], distances2['distance'])  #create new column in df1 to check if prices match\n",
    "\n",
    "    if (df1[df1[0]==i].index.values % 500 == 0):\n",
    "        print (str(int(df1[df1[0]==i].index.values)) + \" P1 companies have been checked.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_fields_list = cb.get_edge_fields()\n",
    "edges = [(row['__src_id'], row['__dst_id'], dict(list(row.items())[2:])) for row in cb.edges[edge_fields_list]]\n",
    "vertices_fields_list = cb.get_vertex_fields()\n",
    "nodes = [(row['__id'], dict(list(row.items())[1:])) for row in cb.vertices[vertices_fields_list]]\n",
    "g = nx.Graph()\n",
    "g.add_nodes_from(nodes)\n",
    "g.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Recommender Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying transform:\n",
      "Class             : AutoVectorizer\n",
      "\n",
      "Model Fields\n",
      "------------\n",
      "Features          : ['name', 'type', 'rank', 'roles', 'country_code', 'region', 'status', 'category_groups_list', 'total_funding_usd', 'founded_on', 'closed_on', 'employee_count', 'primary_role', 'p1_tag', 'p1_date']\n",
      "Excluded Features : ['uuid']\n",
      "\n",
      "Column                Type   Interpretation  Transforms                         Output Type\n",
      "--------------------  -----  --------------  ---------------------------------  -----------\n",
      "name                  str    categorical     None                               str        \n",
      "type                  str    categorical     None                               str        \n",
      "rank                  float  numerical       None                               float      \n",
      "roles                 str    categorical     None                               str        \n",
      "country_code          str    categorical     None                               str        \n",
      "region                str    categorical     None                               str        \n",
      "status                str    categorical     None                               str        \n",
      "category_groups_list  str    short_text      3-Character NGram Counts -> TFIDF  dict       \n",
      "total_funding_usd     float  numerical       None                               float      \n",
      "founded_on            str    categorical     None                               str        \n",
      "closed_on             str    categorical     None                               str        \n",
      "employee_count        str    categorical     None                               str        \n",
      "primary_role          str    categorical     None                               str        \n",
      "p1_tag                int    categorical     astype(str)                        str        \n",
      "p1_date               str    categorical     None                               str        \n",
      "\n",
      "\n",
      "Defaulting to brute force instead of ball tree because there are multiple distance components.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting brute force nearest neighbors model training.</pre>"
      ],
      "text/plain": [
       "Starting brute force nearest neighbors model training."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Validating distance components.</pre>"
      ],
      "text/plain": [
       "Validating distance components."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Initializing model data.</pre>"
      ],
      "text/plain": [
       "Initializing model data."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Initializing distances.</pre>"
      ],
      "text/plain": [
       "Initializing distances."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Done.</pre>"
      ],
      "text/plain": [
       "Done."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting pairwise querying.</pre>"
      ],
      "text/plain": [
       "Starting pairwise querying."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+--------------+---------+-------------+--------------+</pre>"
      ],
      "text/plain": [
       "+--------------+---------+-------------+--------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Query points | # Pairs | % Complete. | Elapsed Time |</pre>"
      ],
      "text/plain": [
       "| Query points | # Pairs | % Complete. | Elapsed Time |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+--------------+---------+-------------+--------------+</pre>"
      ],
      "text/plain": [
       "+--------------+---------+-------------+--------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2            | 2424    | 0.165017    | 26.683ms     |</pre>"
      ],
      "text/plain": [
       "| 2            | 2424    | 0.165017    | 26.683ms     |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Done         |         | 100         | 723.701ms    |</pre>"
      ],
      "text/plain": [
       "| Done         |         | 100         | 723.701ms    |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+--------------+---------+-------------+--------------+</pre>"
      ],
      "text/plain": [
       "+--------------+---------+-------------+--------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Preparing data set.</pre>"
      ],
      "text/plain": [
       "Preparing data set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>    Data has 0 observations with 0 users and 1212 items.</pre>"
      ],
      "text/plain": [
       "    Data has 0 observations with 0 users and 1212 items."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>    Data prepared in: 0.191184s</pre>"
      ],
      "text/plain": [
       "    Data prepared in: 0.191184s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Loading user-provided nearest items.</pre>"
      ],
      "text/plain": [
       "Loading user-provided nearest items."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Generating candidate set for working with new users.</pre>"
      ],
      "text/plain": [
       "Generating candidate set for working with new users."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished training in 0.019975s</pre>"
      ],
      "text/plain": [
       "Finished training in 0.019975s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from turicreate import recommender\n",
    "pruned_frame = cb_sframes[1].dropna()\n",
    "m = recommender.item_content_recommender.create(pruned_frame, \"uuid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Turicreate Model </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n",
      "PROGRESS: The following methods are available for this type of problem.\n",
      "PROGRESS: LogisticClassifier, SVMClassifier\n",
      "PROGRESS: The returned model will be chosen according to validation accuracy.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 1151</pre>"
      ],
      "text/plain": [
       "Number of examples          : 1151"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 3</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 3</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients      : 815</pre>"
      ],
      "text/plain": [
       "Number of coefficients      : 815"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training Accuracy | Validation Accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training Accuracy | Validation Accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 0         | 2        | 1.000000  | 0.005797     | 0.993918          | 0.983607            |</pre>"
      ],
      "text/plain": [
       "| 0         | 2        | 1.000000  | 0.005797     | 0.993918          | 0.983607            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 4        | 1.000000  | 0.011045     | 0.995656          | 0.983607            |</pre>"
      ],
      "text/plain": [
       "| 1         | 4        | 1.000000  | 0.011045     | 0.995656          | 0.983607            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 6        | 1.000000  | 0.015012     | 0.995656          | 0.983607            |</pre>"
      ],
      "text/plain": [
       "| 2         | 6        | 1.000000  | 0.015012     | 0.995656          | 0.983607            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 8        | 1.000000  | 0.018101     | 0.996525          | 0.983607            |</pre>"
      ],
      "text/plain": [
       "| 3         | 8        | 1.000000  | 0.018101     | 0.996525          | 0.983607            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 10       | 1.000000  | 0.020876     | 0.995656          | 0.983607            |</pre>"
      ],
      "text/plain": [
       "| 4         | 10       | 1.000000  | 0.020876     | 0.995656          | 0.983607            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 9         | 22       | 2.939823  | 0.041804     | 0.995656          | 0.983607            |</pre>"
      ],
      "text/plain": [
       "| 9         | 22       | 2.939823  | 0.041804     | 0.995656          | 0.983607            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>SVM:</pre>"
      ],
      "text/plain": [
       "SVM:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 1151</pre>"
      ],
      "text/plain": [
       "Number of examples          : 1151"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 3</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 3</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 815</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 815"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting L-BFGS</pre>"
      ],
      "text/plain": [
       "Starting L-BFGS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training Accuracy | Validation Accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training Accuracy | Validation Accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 0         | 2        | 1.000000  | 0.004354     | 0.993918          | 0.983607            |</pre>"
      ],
      "text/plain": [
       "| 0         | 2        | 1.000000  | 0.004354     | 0.993918          | 0.983607            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 4        | 1.000000  | 0.007264     | 0.993918          | 0.983607            |</pre>"
      ],
      "text/plain": [
       "| 1         | 4        | 1.000000  | 0.007264     | 0.993918          | 0.983607            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 5        | 1.000000  | 0.009068     | 0.995656          | 0.983607            |</pre>"
      ],
      "text/plain": [
       "| 2         | 5        | 1.000000  | 0.009068     | 0.995656          | 0.983607            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 6        | 1.000000  | 0.010500     | 0.995656          | 0.983607            |</pre>"
      ],
      "text/plain": [
       "| 3         | 6        | 1.000000  | 0.010500     | 0.995656          | 0.983607            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 7        | 1.000000  | 0.012375     | 0.995656          | 0.983607            |</pre>"
      ],
      "text/plain": [
       "| 4         | 7        | 1.000000  | 0.012375     | 0.995656          | 0.983607            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 9         | 15       | 0.120824  | 0.023793     | 0.995656          | 0.983607            |</pre>"
      ],
      "text/plain": [
       "| 9         | 15       | 0.120824  | 0.023793     | 0.995656          | 0.983607            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Model selection based on validation accuracy:\n",
      "PROGRESS: ---------------------------------------------\n",
      "PROGRESS: LogisticClassifier              : 0.983606557377\n",
      "PROGRESS: SVMClassifier                   : 0.983606557377\n",
      "PROGRESS: ---------------------------------------------\n",
      "PROGRESS: Selecting LogisticClassifier based on validation set performance.\n"
     ]
    }
   ],
   "source": [
    "from turicreate import classifier\n",
    "pruned_frame = cb_sframes[1].dropna()\n",
    "\n",
    "model = classifier.create(pruned_frame, target='p1_tag',features=['category_groups_list', 'founded_on', 'type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.995049504950495,\n",
       " 'auc': 0.984692179700499,\n",
       " 'confusion_matrix': Columns:\n",
       " \ttarget_label\tint\n",
       " \tpredicted_label\tint\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 3\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+-------+\n",
       " | target_label | predicted_label | count |\n",
       " +--------------+-----------------+-------+\n",
       " |      1       |        0        |   6   |\n",
       " |      1       |        1        |   4   |\n",
       " |      0       |        0        |  1202 |\n",
       " +--------------+-----------------+-------+\n",
       " [3 rows x 3 columns],\n",
       " 'f1_score': 0.5714285714285715,\n",
       " 'log_loss': 0.017233967475003508,\n",
       " 'precision': 1.0,\n",
       " 'recall': 0.4,\n",
       " 'roc_curve': Columns:\n",
       " \tthreshold\tfloat\n",
       " \tfpr\tfloat\n",
       " \ttpr\tfloat\n",
       " \tp\tint\n",
       " \tn\tint\n",
       " \n",
       " Rows: 1001\n",
       " \n",
       " Data:\n",
       " +-----------+-----------------+-----+----+------+\n",
       " | threshold |       fpr       | tpr | p  |  n   |\n",
       " +-----------+-----------------+-----+----+------+\n",
       " |    0.0    |       1.0       | 1.0 | 10 | 1202 |\n",
       " |   0.001   |  0.158901830283 | 1.0 | 10 | 1202 |\n",
       " |   0.002   |  0.114808652246 | 1.0 | 10 | 1202 |\n",
       " |   0.003   | 0.0973377703827 | 1.0 | 10 | 1202 |\n",
       " |   0.004   | 0.0806988352745 | 0.9 | 10 | 1202 |\n",
       " |   0.005   | 0.0732113144759 | 0.9 | 10 | 1202 |\n",
       " |   0.006   | 0.0698835274542 | 0.9 | 10 | 1202 |\n",
       " |   0.007   | 0.0698835274542 | 0.9 | 10 | 1202 |\n",
       " |   0.008   | 0.0623960066556 | 0.9 | 10 | 1202 |\n",
       " |   0.009   | 0.0623960066556 | 0.9 | 10 | 1202 |\n",
       " +-----------+-----------------+-----+----+------+\n",
       " [1001 rows x 5 columns]\n",
       " Note: Only the head of the SFrame is printed.\n",
       " You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(pruned_frame)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pruned_frame[pruned_frame['p1_tag'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
